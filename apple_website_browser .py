#!/usr/bin/env python3
"""
Apple Japan Website Browser
ä½¿ç”¨ Playwright è‡ªåŠ¨æµè§ˆ Apple æ—¥æœ¬å®˜ç½‘çš„è„šæœ¬
æ”¯æŒ Windows å’Œ Mac ç³»ç»Ÿ
"""

import asyncio
import random
import time
import platform
from playwright.async_api import async_playwright
import logging
try:
    from blocked_urls import get_blocked_patterns_js, filter_links
except ImportError:
    # å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œä½¿ç”¨å†…ç½®çš„å±è”½é€»è¾‘
    def get_blocked_patterns_js():
        return "['search', '/search', '/search/', 'apple.com/jp/search']"

    def filter_links(links):
        blocked_patterns = ['search']
        filtered = []
        for link in links:
            url = link.get('url', '') if isinstance(link, dict) else str(link)
            if not any(pattern in url.lower() for pattern in blocked_patterns):
                filtered.append(link)
        return filtered

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('browser_log.txt', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class AppleWebsiteBrowser:
    def __init__(self, browse_duration=60, major_cycles=3, max_retries=3, retry_delay=5):
        """
        åˆå§‹åŒ–æµè§ˆå™¨é…ç½®

        Args:
            browse_duration (int): æ¯ä¸ªé¡µé¢çš„æµè§ˆæ—¶é—´ï¼ˆç§’ï¼‰
            major_cycles (int): å¤§å¾ªç¯æ¬¡æ•°ï¼Œæ¯ä¸ªå¤§å¾ªç¯åŒ…å«8æ¬¡é¡µé¢è®¿é—®
            max_retries (int): æœ€å¤§é‡è¯•æ¬¡æ•°
            retry_delay (int): é‡è¯•é—´éš”æ—¶é—´ï¼ˆç§’ï¼‰
        """
        self.browse_duration = browse_duration
        self.major_cycles = major_cycles
        self.minor_cycles_per_major = 8  # å›ºå®šå€¼ï¼Œæ¯ä¸ªå¤§å¾ªç¯åŒ…å«8æ¬¡é¡µé¢è®¿é—®
        self.base_url = "https://www.apple.com/jp/"
        self.visited_links = []
        self.available_links = []
        self.current_major_cycle = 0
        self.current_minor_cycle = 0

        # é‡è¯•æœºåˆ¶é…ç½®
        self.max_retries = max_retries
        self.retry_delay = retry_delay
        self.retry_stats = {
            'total_retries': 0,
            'successful_retries': 0,
            'failed_operations': 0
        }

    async def retry_operation(self, operation_name, operation_func, *args, **kwargs):
        """
        é€šç”¨é‡è¯•æœºåˆ¶

        Args:
            operation_name (str): æ“ä½œåç§°ï¼Œç”¨äºæ—¥å¿—
            operation_func: è¦é‡è¯•çš„å¼‚æ­¥å‡½æ•°
            *args, **kwargs: ä¼ é€’ç»™æ“ä½œå‡½æ•°çš„å‚æ•°

        Returns:
            æ“ä½œå‡½æ•°çš„è¿”å›å€¼ï¼Œå¦‚æœæ‰€æœ‰é‡è¯•éƒ½å¤±è´¥åˆ™è¿”å›None
        """
        for attempt in range(self.max_retries + 1):  # +1 å› ä¸ºç¬¬ä¸€æ¬¡ä¸ç®—é‡è¯•
            try:
                if attempt > 0:
                    logger.warning(f"ğŸ”„ {operation_name} - ç¬¬ {attempt} æ¬¡é‡è¯•")
                    self.retry_stats['total_retries'] += 1
                    await asyncio.sleep(self.retry_delay)

                result = await operation_func(*args, **kwargs)

                if attempt > 0:
                    logger.info(f"âœ… {operation_name} - é‡è¯•æˆåŠŸ")
                    self.retry_stats['successful_retries'] += 1

                return result

            except Exception as e:
                if attempt < self.max_retries:
                    logger.warning(f"âš ï¸ {operation_name} - å°è¯• {attempt + 1} å¤±è´¥: {e}")
                    logger.info(f"â³ ç­‰å¾… {self.retry_delay} ç§’åé‡è¯•...")
                else:
                    logger.error(f"âŒ {operation_name} - æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥: {e}")
                    self.retry_stats['failed_operations'] += 1
                    return None

    async def safe_goto(self, page, url, timeout=30000):
        """
        å®‰å…¨çš„é¡µé¢å¯¼èˆªï¼Œå¸¦é‡è¯•æœºåˆ¶

        Args:
            page: Playwright é¡µé¢å¯¹è±¡
            url (str): ç›®æ ‡URL
            timeout (int): è¶…æ—¶æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰

        Returns:
            bool: æ˜¯å¦æˆåŠŸå¯¼èˆª
        """
        async def _goto_operation():
            await page.goto(url, wait_until="domcontentloaded", timeout=timeout)
            await page.wait_for_load_state("networkidle", timeout=10000)
            return True

        result = await self.retry_operation(f"å¯¼èˆªåˆ° {url}", _goto_operation)
        return result is not None

    async def safe_evaluate(self, page, script, description="æ‰§è¡Œè„šæœ¬"):
        """
        å®‰å…¨çš„é¡µé¢è„šæœ¬æ‰§è¡Œï¼Œå¸¦é‡è¯•æœºåˆ¶

        Args:
            page: Playwright é¡µé¢å¯¹è±¡
            script (str): è¦æ‰§è¡Œçš„JavaScriptä»£ç 
            description (str): æ“ä½œæè¿°

        Returns:
            è„šæœ¬æ‰§è¡Œç»“æœï¼Œå¤±è´¥æ—¶è¿”å›None
        """
        async def _evaluate_operation():
            return await page.evaluate(script)

        return await self.retry_operation(description, _evaluate_operation)

    async def precise_browse_page(self, page, duration):
        """
        ç²¾ç¡®æ§åˆ¶é¡µé¢æµè§ˆæ—¶é—´ï¼šæ»šåŠ¨é˜¶æ®µ + ç­‰å¾…é˜¶æ®µ

        Args:
            page: Playwright é¡µé¢å¯¹è±¡
            duration (int): æ€»æµè§ˆæ—¶é—´ï¼ˆç§’ï¼‰
        """
        total_start_time = time.time()
        logger.info(f"å¼€å§‹ç²¾ç¡®æµè§ˆé¡µé¢ï¼Œæ€»æ—¶é•¿: {duration}ç§’")

        # é˜¶æ®µ1: æ»šåŠ¨åˆ°åº•éƒ¨
        scroll_start_time = time.time()
        await self._scroll_to_bottom(page)
        scroll_end_time = time.time()
        scroll_duration = scroll_end_time - scroll_start_time

        logger.info(f"æ»šåŠ¨é˜¶æ®µå®Œæˆï¼Œè€—æ—¶: {scroll_duration:.2f}ç§’")

        # é˜¶æ®µ2: åœ¨åº•éƒ¨ç­‰å¾…å‰©ä½™æ—¶é—´
        elapsed_time = time.time() - total_start_time
        remaining_time = max(0, duration - elapsed_time)

        if remaining_time > 0:
            logger.info(f"åœ¨é¡µé¢åº•éƒ¨ç­‰å¾…å‰©ä½™æ—¶é—´: {remaining_time:.2f}ç§’")
            await asyncio.sleep(remaining_time)

        total_duration = time.time() - total_start_time
        logger.info(f"é¡µé¢æµè§ˆå®Œæˆï¼Œå®é™…æ€»è€—æ—¶: {total_duration:.2f}ç§’")

        return total_duration

    async def _scroll_to_bottom(self, page):
        """
        å‘ä¸‹æ»šåŠ¨ç›´åˆ°é¡µé¢åº•éƒ¨ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰

        Args:
            page: Playwright é¡µé¢å¯¹è±¡

        Returns:
            bool: æ˜¯å¦æˆåŠŸæ»šåŠ¨åˆ°åº•éƒ¨
        """
        logger.info("å¼€å§‹å‘ä¸‹æ»šåŠ¨åˆ°é¡µé¢åº•éƒ¨")

        scroll_position = 0
        scroll_count = 0
        consecutive_failures = 0
        max_consecutive_failures = 3

        while True:
            # å®‰å…¨è·å–é¡µé¢ä¿¡æ¯
            page_info = await self.safe_evaluate(
                page,
                """
                () => ({
                    scrollHeight: document.body.scrollHeight,
                    clientHeight: window.innerHeight,
                    scrollTop: window.pageYOffset
                })
                """,
                "è·å–é¡µé¢æ»šåŠ¨ä¿¡æ¯"
            )

            if page_info is None:
                consecutive_failures += 1
                logger.warning(f"è·å–é¡µé¢ä¿¡æ¯å¤±è´¥ï¼Œè¿ç»­å¤±è´¥æ¬¡æ•°: {consecutive_failures}")

                if consecutive_failures >= max_consecutive_failures:
                    logger.error("è¿ç»­è·å–é¡µé¢ä¿¡æ¯å¤±è´¥ï¼Œåœæ­¢æ»šåŠ¨")
                    return False

                await asyncio.sleep(2)  # ç­‰å¾…åé‡è¯•
                continue

            # é‡ç½®è¿ç»­å¤±è´¥è®¡æ•°
            consecutive_failures = 0

            # æ£€æŸ¥æ˜¯å¦å·²åˆ°è¾¾åº•éƒ¨
            max_scroll = page_info['scrollHeight'] - page_info['clientHeight']
            if scroll_position >= max_scroll:
                logger.info(f"å·²åˆ°è¾¾é¡µé¢åº•éƒ¨ï¼Œæ€»å…±æ»šåŠ¨ {scroll_count} æ¬¡")
                break

            # å‘ä¸‹æ»šåŠ¨
            scroll_distance = random.randint(100, 250)
            scroll_position = min(scroll_position + scroll_distance, max_scroll)

            # å®‰å…¨æ‰§è¡Œæ»šåŠ¨
            try:
                await page.evaluate(f"window.scrollTo({{top: {scroll_position}, behavior: 'smooth'}})")
                scroll_count += 1
            except Exception as e:
                logger.warning(f"æ»šåŠ¨æ“ä½œå¤±è´¥: {e}ï¼Œç»§ç»­å°è¯•")
                # å³ä½¿æ»šåŠ¨å¤±è´¥ï¼Œä¹Ÿè¦æ›´æ–°ä½ç½®ï¼Œé¿å…æ— é™å¾ªç¯
                pass

            # éšæœºåœé¡¿ï¼Œæ¨¡æ‹ŸçœŸå®ç”¨æˆ·è¡Œä¸º
            pause_time = random.uniform(0.5, 1.5)
            await asyncio.sleep(pause_time)

            # å¶å°”é•¿æ—¶é—´åœé¡¿ï¼Œæ¨¡æ‹Ÿé˜…è¯»
            if random.random() < 0.1:  # 10% æ¦‚ç‡
                reading_time = random.uniform(1.0, 3.0)
                await asyncio.sleep(reading_time)

        return True

    async def refresh_links(self, page):
        """
        åˆ·æ–°é“¾æ¥åˆ—è¡¨ï¼šè¿”å›ä¸»é¡µå¹¶é‡æ–°è·å–æ‰€æœ‰å¯ç”¨é“¾æ¥ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰

        Args:
            page: Playwright é¡µé¢å¯¹è±¡

        Returns:
            bool: æ˜¯å¦æˆåŠŸåˆ·æ–°é“¾æ¥
        """
        logger.info("=== å¼€å§‹åˆ·æ–°é“¾æ¥åˆ—è¡¨ ===")

        # å®‰å…¨è¿”å›ä¸»é¡µ
        homepage_success = await self.safe_goto(page, self.base_url)
        if not homepage_success:
            logger.error("æ— æ³•è¿”å›ä¸»é¡µï¼Œé“¾æ¥åˆ·æ–°å¤±è´¥")
            return False

        logger.info("å·²è¿”å›ä¸»é¡µ")

        # æ¸…ç©ºè®¿é—®è®°å½•
        self.visited_links.clear()
        logger.info("å·²æ¸…ç©ºè®¿é—®è®°å½•")

        # é‡æ–°è·å–é“¾æ¥ï¼ˆå¸¦é‡è¯•ï¼‰
        async def _get_links_operation():
            return await self.get_navigation_links(page)

        self.available_links = await self.retry_operation("è·å–å¯¼èˆªé“¾æ¥", _get_links_operation)

        if self.available_links is None:
            self.available_links = []
            logger.error("è·å–é“¾æ¥å¤±è´¥ï¼Œä½¿ç”¨ç©ºé“¾æ¥åˆ—è¡¨")
            return False

        logger.info(f"é‡æ–°è·å–åˆ° {len(self.available_links)} ä¸ªå¯ç”¨é“¾æ¥")
        return len(self.available_links) > 0

    async def get_navigation_links(self, page):
        """
        è·å–é¡µé¢ä¸­çš„å¯¼èˆªé“¾æ¥ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰

        Args:
            page: Playwright é¡µé¢å¯¹è±¡

        Returns:
            list: é“¾æ¥åˆ—è¡¨ï¼Œå¤±è´¥æ—¶è¿”å›ç©ºåˆ—è¡¨
        """
        # è·å–ä¸»å¯¼èˆªé“¾æ¥
        links = await self.safe_evaluate(
            page,
            """
            () => {
                const links = [];
                try {
                    // è·å–ä¸»å¯¼èˆªèœå•é“¾æ¥
                    const navLinks = document.querySelectorAll('nav a, .globalnav a, .ac-gn-link');
                    navLinks.forEach(link => {
                        if (link.href && link.href.includes('apple.com/jp/') &&
                            !link.href.includes('#') &&
                            link.href !== window.location.href) {
                            links.push({
                                url: link.href,
                                text: link.textContent.trim()
                            });
                        }
                    });

                    // è·å–äº§å“é¡µé¢é“¾æ¥
                    const productLinks = document.querySelectorAll('.tile a, .product-tile a, .hero a');
                    productLinks.forEach(link => {
                        if (link.href && link.href.includes('apple.com/jp/') &&
                            !link.href.includes('#') &&
                            link.href !== window.location.href) {
                            links.push({
                                url: link.href,
                                text: link.textContent.trim()
                            });
                        }
                    });

                    return links;
                } catch (error) {
                    console.error('è·å–é“¾æ¥æ—¶å‡ºé”™:', error);
                    return [];
                }
            }
            """,
            "è·å–é¡µé¢å¯¼èˆªé“¾æ¥"
        )

        if links is None:
            logger.error("è·å–é“¾æ¥å¤±è´¥")
            return []

        # å»é‡å¹¶è¿‡æ»¤å±è”½çš„é“¾æ¥
        unique_links = []
        seen_urls = set()
        for link in links:
            if link['url'] not in seen_urls:
                unique_links.append(link)
                seen_urls.add(link['url'])

        # è¿‡æ»¤å±è”½çš„é“¾æ¥
        filtered_links = filter_links(unique_links)

        logger.info(f"æ‰¾åˆ° {len(unique_links)} ä¸ªå”¯ä¸€é“¾æ¥ï¼Œè¿‡æ»¤åå‰©ä½™ {len(filtered_links)} ä¸ª")
        return filtered_links

    async def browse_page(self, page, url, duration):
        """
        ç²¾ç¡®æµè§ˆæŒ‡å®šé¡µé¢ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰

        Args:
            page: Playwright é¡µé¢å¯¹è±¡
            url (str): è¦æµè§ˆçš„URL
            duration (int): æµè§ˆæ—¶é—´ï¼ˆç§’ï¼‰

        Returns:
            float: å®é™…æµè§ˆæ—¶é—´ï¼Œå¤±è´¥æ—¶è¿”å›0
        """
        # è·å–å½“å‰é¡µé¢æ ‡é¢˜ï¼ˆç”¨äºæ—¥å¿—ï¼‰
        try:
            current_title = await page.title() if page.url else "æœªçŸ¥é¡µé¢"
        except:
            current_title = "æ— æ³•è·å–æ ‡é¢˜"

        logger.info(f"ç¬¬ {self.current_minor_cycle}/8 æ¬¡é¡µé¢è®¿é—®")
        logger.info(f"æ­£åœ¨è®¿é—®: {url}")
        logger.info(f"å½“å‰é¡µé¢: {current_title}")

        # å®‰å…¨å¯¼èˆªåˆ°é¡µé¢
        navigation_success = await self.safe_goto(page, url)
        if not navigation_success:
            logger.error(f"æ— æ³•å¯¼èˆªåˆ°é¡µé¢: {url}")
            return 0

        # å®‰å…¨è·å–æ–°çš„é¡µé¢æ ‡é¢˜
        page_title = await self.safe_evaluate(
            page,
            "document.title",
            "è·å–é¡µé¢æ ‡é¢˜"
        )

        if page_title:
            logger.info(f"é¡µé¢åŠ è½½å®Œæˆ: {page_title}")
        else:
            logger.warning("æ— æ³•è·å–é¡µé¢æ ‡é¢˜ï¼Œä½†ç»§ç»­æµè§ˆ")

        # è®°å½•è®¿é—®çš„é“¾æ¥
        self.visited_links.append(url)

        # ç²¾ç¡®æ§åˆ¶æµè§ˆæ—¶é—´ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰
        try:
            actual_duration = await self.precise_browse_page(page, duration)
            return actual_duration
        except Exception as e:
            logger.error(f"æµè§ˆé¡µé¢å†…å®¹æ—¶å‡ºé”™: {e}")
            # å³ä½¿æµè§ˆå¤±è´¥ï¼Œä¹Ÿè¦ç­‰å¾…æŒ‡å®šæ—¶é—´ï¼Œä¿æŒæ—¶é—´ä¸€è‡´æ€§
            logger.info(f"æµè§ˆå¤±è´¥ï¼Œä½†ä»ç­‰å¾… {duration} ç§’ä¿æŒæ—¶é—´ä¸€è‡´æ€§")
            await asyncio.sleep(duration)
            return duration

    async def run(self):
        """
        è¿è¡ŒåŒå±‚å¾ªç¯æµè§ˆæµç¨‹
        """
        total_pages = self.major_cycles * self.minor_cycles_per_major

        logger.info("å¼€å§‹å¯åŠ¨æµè§ˆå™¨...")
        logger.info(f"ç³»ç»Ÿ: {platform.system()}")
        logger.info(f"æµè§ˆæ—¶é•¿: {self.browse_duration}ç§’/é¡µé¢")
        logger.info(f"å¤§å¾ªç¯æ¬¡æ•°: {self.major_cycles}")
        logger.info(f"æ¯ä¸ªå¤§å¾ªç¯åŒ…å«: {self.minor_cycles_per_major} æ¬¡é¡µé¢è®¿é—®")
        logger.info(f"æ€»é¡µé¢è®¿é—®æ¬¡æ•°: {total_pages}")

        async with async_playwright() as p:
            # æ ¹æ®ç³»ç»Ÿé€‰æ‹©æµè§ˆå™¨
            if platform.system() == "Darwin":  # Mac
                browser = await p.webkit.launch(headless=False)
            else:  # Windows å’Œå…¶ä»–ç³»ç»Ÿ
                browser = await p.chromium.launch(headless=False)

            context = await browser.new_context(
                viewport={"width": 1920, "height": 1080},
                user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
            )

            page = await context.new_page()

            try:
                # å¤–å±‚å¾ªç¯ï¼šå¤§å¾ªç¯
                for major_cycle in range(self.major_cycles):
                    self.current_major_cycle = major_cycle + 1
                    logger.info(f"=== å¤§å¾ªç¯ {self.current_major_cycle}/{self.major_cycles} å¼€å§‹ ===")

                    # åˆ·æ–°é“¾æ¥åˆ—è¡¨
                    links_available = await self.refresh_links(page)
                    if not links_available:
                        logger.error("æ— æ³•è·å–å¯ç”¨é“¾æ¥ï¼Œè·³è¿‡æ­¤å¤§å¾ªç¯")
                        continue

                    # å†…å±‚å¾ªç¯ï¼š8æ¬¡é¡µé¢è®¿é—®
                    for minor_cycle in range(self.minor_cycles_per_major):
                        self.current_minor_cycle = minor_cycle + 1
                        page_number = major_cycle * self.minor_cycles_per_major + minor_cycle + 1

                        logger.info(f"--- å¤§å¾ªç¯ {self.current_major_cycle}, å°å¾ªç¯ {self.current_minor_cycle}/8 (æ€»ç¬¬ {page_number}/{total_pages} é¡µ) ---")

                        # éšæœºé€‰æ‹©é“¾æ¥
                        if self.available_links:
                            selected_link = random.choice(self.available_links)
                            logger.info(f"éšæœºé€‰æ‹©é“¾æ¥: {selected_link['text']} ({selected_link['url']})")

                            # æµè§ˆé¡µé¢
                            actual_duration = await self.browse_page(
                                page, selected_link['url'], self.browse_duration
                            )

                            logger.info(f"é¡µé¢æµè§ˆå®Œæˆï¼Œå®é™…è€—æ—¶: {actual_duration:.2f}ç§’")
                        else:
                            logger.warning("æ²¡æœ‰å¯ç”¨é“¾æ¥ï¼Œæµè§ˆä¸»é¡µ")
                            await self.browse_page(page, self.base_url, self.browse_duration)

                    logger.info(f"=== å¤§å¾ªç¯ {self.current_major_cycle}/{self.major_cycles} å®Œæˆ ===")

                logger.info("ğŸ‰ æ‰€æœ‰æµè§ˆå¾ªç¯å®Œæˆï¼")

                # è¾“å‡ºé‡è¯•ç»Ÿè®¡ä¿¡æ¯
                logger.info("=" * 50)
                logger.info("ğŸ“Š é‡è¯•æœºåˆ¶ç»Ÿè®¡æŠ¥å‘Š")
                logger.info("=" * 50)
                logger.info(f"æ€»é‡è¯•æ¬¡æ•°: {self.retry_stats['total_retries']}")
                logger.info(f"æˆåŠŸé‡è¯•æ¬¡æ•°: {self.retry_stats['successful_retries']}")
                logger.info(f"å¤±è´¥æ“ä½œæ¬¡æ•°: {self.retry_stats['failed_operations']}")

                if self.retry_stats['total_retries'] > 0:
                    success_rate = (self.retry_stats['successful_retries'] / self.retry_stats['total_retries']) * 100
                    logger.info(f"é‡è¯•æˆåŠŸç‡: {success_rate:.1f}%")
                else:
                    logger.info("é‡è¯•æˆåŠŸç‡: 100% (æ— éœ€é‡è¯•)")

                logger.info("=" * 50)

            except Exception as e:
                logger.error(f"æµè§ˆè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
                logger.info("ç¨‹åºå¼‚å¸¸ç»“æŸï¼Œè¾“å‡ºé‡è¯•ç»Ÿè®¡:")
                logger.info(f"æ€»é‡è¯•æ¬¡æ•°: {self.retry_stats['total_retries']}")
                logger.info(f"å¤±è´¥æ“ä½œæ¬¡æ•°: {self.retry_stats['failed_operations']}")

            finally:
                await browser.close()

def main():
    """
    ä¸»å‡½æ•°
    """
    print("Apple Japan Website Browser - åŒå±‚å¾ªç¯ç‰ˆæœ¬ (å¸¦é‡è¯•æœºåˆ¶)")
    print("=" * 70)
    print("åŠŸèƒ½è¯´æ˜ï¼š")
    print("- å¤§å¾ªç¯ï¼šæ¯ä¸ªå¤§å¾ªç¯åŒ…å«8æ¬¡é¡µé¢è®¿é—®")
    print("- å°å¾ªç¯ï¼šæ¯æ¬¡é¡µé¢è®¿é—®åŒ…å«æ»šåŠ¨+ç­‰å¾…é˜¶æ®µ")
    print("- æ€»è®¿é—®æ¬¡æ•° = å¤§å¾ªç¯æ¬¡æ•° Ã— 8")
    print("- é‡è¯•æœºåˆ¶ï¼šè‡ªåŠ¨å¤„ç†ç½‘ç»œé—®é¢˜å’Œé¡µé¢åŠ è½½å¤±è´¥")
    print("=" * 70)

    # ç”¨æˆ·å¯ä»¥è‡ªå®šä¹‰é…ç½®
    try:
        duration = int(input("è¯·è¾“å…¥æ¯é¡µæµè§ˆæ—¶é—´ï¼ˆç§’ï¼Œé»˜è®¤60ï¼‰: ") or "60")
        major_cycles = int(input("è¯·è¾“å…¥å¤§å¾ªç¯æ¬¡æ•°ï¼ˆé»˜è®¤3ï¼Œæ¯ä¸ªå¤§å¾ªç¯8æ¬¡é¡µé¢è®¿é—®ï¼‰: ") or "3")

        # é«˜çº§é…ç½®é€‰é¡¹
        advanced = input("æ˜¯å¦é…ç½®é«˜çº§é€‰é¡¹ï¼Ÿ(y/N): ").lower() == 'y'
        if advanced:
            max_retries = int(input("è¯·è¾“å…¥æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ˆé»˜è®¤3ï¼‰: ") or "3")
            retry_delay = int(input("è¯·è¾“å…¥é‡è¯•é—´éš”æ—¶é—´ï¼ˆç§’ï¼Œé»˜è®¤5ï¼‰: ") or "5")
        else:
            max_retries = 3
            retry_delay = 5

        total_pages = major_cycles * 8
        estimated_time = total_pages * duration / 60  # åˆ†é’Ÿ

        print(f"\né…ç½®ç¡®è®¤ï¼š")
        print(f"- æ¯é¡µæµè§ˆæ—¶é—´: {duration}ç§’")
        print(f"- å¤§å¾ªç¯æ¬¡æ•°: {major_cycles}")
        print(f"- æ€»é¡µé¢è®¿é—®æ¬¡æ•°: {total_pages}")
        print(f"- é¢„è®¡æ€»è€—æ—¶: {estimated_time:.1f}åˆ†é’Ÿ")
        print(f"- æœ€å¤§é‡è¯•æ¬¡æ•°: {max_retries}")
        print(f"- é‡è¯•é—´éš”: {retry_delay}ç§’")

        confirm = input("\nç¡®è®¤å¼€å§‹æµè§ˆï¼Ÿ(y/N): ").lower()
        if confirm != 'y':
            print("å·²å–æ¶ˆ")
            return

    except ValueError:
        duration = 60
        major_cycles = 3
        max_retries = 3
        retry_delay = 5
        print("ä½¿ç”¨é»˜è®¤é…ç½®: 60ç§’/é¡µé¢, 3ä¸ªå¤§å¾ªç¯, 3æ¬¡é‡è¯•")

    browser = AppleWebsiteBrowser(
        browse_duration=duration,
        major_cycles=major_cycles,
        max_retries=max_retries,
        retry_delay=retry_delay
    )
    
    try:
        asyncio.run(browser.run())
    except KeyboardInterrupt:
        print("\nç”¨æˆ·ä¸­æ–­äº†æµè§ˆè¿‡ç¨‹")
    except Exception as e:
        print(f"ç¨‹åºè¿è¡Œå‡ºé”™: {e}")

if __name__ == "__main__":
    main()
